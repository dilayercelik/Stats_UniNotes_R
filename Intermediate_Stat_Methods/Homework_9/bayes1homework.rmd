---
title: "Bayes Homework"
author: "Chris Kelly"
date: "08/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
library(broom)
library(BayesFactor)
library(bayestestR)
```


Run the following code chunk to read in the dataset "Week9_Homework_data.csv" and assign it as an object named "Happiness". This contains simulated data on job satisfaction and happiness in 200 people from 2 different cities; London and New York . 

```{r}
Happiness<- read.csv("Week9_Homework_data.csv")
```

We want to conduct a correlation between two continuous variables: the self reported scores of Happiness and Job Satisfaction scores in our data. 

1. Conduct a Pearson's correlation test using the frequentest approach and store the results in an object called "result".

```{r}
result <- cor.test(Happiness %>% pull(Happiness), 
                   Happiness %>% pull(Job_Satisfaction)) %>% tidy()
```

2. What is the null hypothesis?

The null hypothesis is that there is no significant correlation between the 2 variables, Happiness and Job_Satisfaction. 

3. Would you reject the null hypothesis based on the result?

A Pearson's correlation test, using the Frequentist approach, revealed a significant correlation between the Happiness and Job_Satisfaction variables: t(198) = 2.92, 0.0039 (p<.05).

4. Now conduct the same correlation above but this time from a Bayesian perspective and display the results
  
```{r}
results <- correlationBF(Happiness %>% pull(Happiness), Happiness %>% pull(Job_Satisfaction))

# display the Bayesian results
describe_posterior(results) 
```


5. What is the median of the posterior distribution and how would you interpret this?

The median of the posterior distribution is 0.197, i.e. slightly positive, which means that there is a positive correlation between the Happiness and Job_Satisfaction variables. 

5. Compute the Bayes Factor
  
```{r}
# to compute the Bayes factor comparing 2 models:
# 1: NH (absence of effect)
# 2: AH (presence of effect)
bayesfactor(results)
```

6. How would you interpret the Bayes Factor?

The Bayes factor we obtain, BF = 9.5, is between 3 and 10, which means that there is moderate evidence for the alternative hypothesis, that is, that there is a significant correlation between the Happiness and Job_Satisfaction variables. 

7. Now run a frequentist test to see if there is a difference in Job Satisfaction between London and New York

```{r}
freq_t_test <- t.test(Happiness %>% filter(city=='New York') %>% pull(Job_Satisfaction), 
                      Happiness %>% filter(city=='London') %>% pull(Job_Satisfaction)) %>% tidy()
```

8. What conclusion can you draw from this test?

A frequentist t-test revealed no significant differences in Job Satisfaction ratings between respondents living in London and those living in New York: t = -0.284, p>.05.

9. Now run the Baysian version of this test and compute the BF
  
```{r}
bayes_t_test <- BayesFactor::ttestBF(formula = Job_Satisfaction ~ city, data = Happiness)

describe_posterior(bayes_t_test)
```

10. How would you interpret the BF?

```{r}
# to get the Bayes Factor
bayesfactor(bayes_t_test)
```
The Bayes factor we obtain, BF = 0.16, is between 1/10 and 1/3, which means that there is moderate evidence for the null hypothesis, that is, that there is no significant difference in Job Satisfaction ratings between respondents living in London and those living in New York: this bayes factor provides evidence FOR the null hypothesis of an absence of an effect. 