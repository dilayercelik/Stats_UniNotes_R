---
title: "GLM Introduction: One way ANOVA"
author: "Jo"
date: "24 June 2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,include=FALSE,message=F,warning=F}

library(tidyverse)

```


## Task 1: reverse engineering a decomposition matrix.

To ensure that you have fully understood the relationships between the different components of a decomposition matrix that we learned about this week, the task is to calculate the missing components and then work out the resulting F ratio and p value. Then you will check this against the results of a one-way ANOVA using ezANOVA.

Finally you will complete a t-test in order to compare results and gain a better understanding of the General Linear Model.

Letâ€™s assume that you have data from a one-factor design with three-levels (i.e. one independent variable with three conditions). 

We want to test if interview type affects how interviewers rate the friendliness of candidates. The three types will be in-person, zoom and phone interview. There are 15 participants, 5 in each group.

Our hypothesis is that interview type will influence friendliness ratings, with in-person interviewees rated significantly higher than the other two types.

We will pretend we got sent the decomposition matrix but several columns were missing.

Luckily we know the overall mean friendliness rating; 59.3, and the mean friendliness rating for the three groups; 40.6, 59.2 and 78.2 for phone, zoom and in person respectively.

We also have the ERROR VARIANCES for all 15 candidates:

phone: -3.6 , 0.4 , -6.6 , 5.4 , 4.4

zoom: 6.8, -11.2, -7.2, 6.8, 4.8

in person: 12.8, -12.2, -5.2, 5.8, -1.2

Our first task is to enter the data we do have into a tibble. Create a tibble called `dmx` with column `i` to denote group membership, a column `j` to denote the observation number for that group, a column `mu` with the grand mean and a column `err` with the error variances for each participant. You will also need to add a column called `group_means` which contains the group means which we will use to calculate `Ai` in the next step. 

HINTS. our previous example had 3 groups of 4, this example has 3 groups of 5. 
In our previous example Yij was known and err was calculated, in this example err is known and Yij will need to be derived.

```{r}

dmx <- tibble(i = rep(1:3, each=5), 
              j = rep(1:5, times=3), 
              mu = 59.3, 
              err = c(-3.6 , 0.4 , -6.6 , 5.4 , 4.4,  # error variances for participants in PHONE group 
                      6.8, -11.2, -7.2, 6.8, 4.8,     # error variances for participants in ZOOM group
                      12.8, -12.2, -5.2, 5.8, -1.2),  # error variances for participants in IN-PERSON group
              group_means = rep(c(40.6, 59.2, 78.2), each = 5) # PHONE mean, ZOOM mean, IN-PERSON mean
              
              )
                                                                              
```

We can now derive `Ai` from the grand mean and the group means
HINT. group mean - grand mean = Ai
```{r}

dmx <- dmx %>% mutate(Ai = group_means - mu)

```

Next we can derive Yij using the formula:
Yij - mu - Ai = error

and rearranging it to 
Yij = error + mu + Ai

```{r}
# complete Decomposition Matrix

dmx <- dmx %>% mutate(Yij = mu + Ai + err)

```

Write code to check that the original group means are the mean of the Yij variables in each group (i).

```{r}

mean_group_summary <- dmx %>% group_by(i) %>% summarise(mean_group = mean(Yij))

```
As we can see in the mean_group_summary dataframe we created, the computed means of the Yij variables in each i group are the same as the means in the `group_means` column of dmx (which were the 'original' group means we were given).



Now that we have our dependent variable (Yij), we can plot the data in a boxplot. Plot Yij by group. 
HINT: you will need to tell R that group is a factor using `as.factor(i)` within aes()

```{r}
# visualisation

ggplot(dmx, aes(x=as.factor(i), y=Yij, color=as.factor(i))) +
  geom_violin() +
  geom_boxplot(width=0.4) +
  labs(title='Boxplots of the Friendliness Ratings (DV) in function of interview type (IV/factor)', x='Interview Type', y='Friendliness Rating') +
  theme_classic() +
  scale_color_manual(labels = c('Interview Type 1: Phone', 'Interview Type 2: Zoom', 'Interview Type 3: In-Person'), values = c('red', 'blue', 'green')) +
  scale_colour_discrete('Legend') 

```
# Notes: code forums I have used to make my plot prettier:
- https://stackoverflow.com/questions/23635662/editing-legend-text-labels-in-ggplot
- https://stackoverflow.com/questions/23635662/editing-legend-text-labels-in-ggplot


Based on the graph do you think we will observe a significant group difference?

WRITE ANSWER: From the boxplots above, our intuition is that the groups are significantly different from each other (interview type seems likely to have a significant effect on friendliness ratings): this can be seen by the lack of spatial overlap between the 3 boxplots and their visibly very different median values, although we need to use inferential statistics to properly state a significant group difference.


Next create the sum of squares table. Call this `sstable`
```{r}
# sum of squares table

sstable <- dmx %>% summarise(SS_mu=sum(mu^2),
                             SS_Ai=sum(Ai^2),
                             SS_err=sum(err^2)
                             )
```

Save the degrees of freedom for Ai as df_num (HINT k-1)
```{r}
# df for Ai (or df_effect)
# equal to num of groups - 1

df_num = 3 - 1

```

Save the degrees of freedom for error term as df_denom (HINT n - df_num - 1)
```{r}
# df for error term (or df_error)
# equal to total num of participants - num of groups

df_denom = 15 - 3

```

Calculate MSA, where A is the factor 'interview type'. Save this value as `MSA`
HINT: Use pull() or $ to extract the sum of squares you need from `sstable`
```{r}
# MSA

MSA = sstable$SS_Ai / df_num   

```

Calculate mean squared error. Save this value as `MSSA`
```{r}
# MSSA

MSSA = sstable$SS_err / df_denom

```

Use your 2 saved values, `MSA` and `MSSA` to calculate the F ratio and save this as `Fval`

```{r}

# Computing the F ratio 

Fval = MSA / MSSA

```

Interpret the F statistic by calculating the p-value of it occurring by chance
```{r}

pval = pf(Fval, df_num, df_denom, lower.tail=FALSE)

```


# Do it the easy way using ezANOVA()
```{r}
# first, we load the 'ez' package
library(ez)

# second, we add an ID column to dmx (needed for ezANOVA() function)
dmx <- dmx %>% mutate(ID=1:15,i=as.factor(i)) 

```

```{r}
# note to myself: look at the first data.frame for ANOVA output (second one: Levene's Test output)
ezANOVA(data=dmx, 
        wid=ID,  
        dv=Yij, 
        between=i,  # IV/factor of our one-way ANOVA
        detailed=TRUE
        )

```

Report F, p and effect size

WRITE ANSWER: F(2, 12) = 27.44, p < .05, ges = .82


# EXTENSION WORK

We are going to remove the phone interview participants (i=1) and rerun the ANOVA with only two factors. First create a new object `dmx4` with i=1 filtered out. 

```{r}

dmx4 <- dmx %>% filter(!i==1)

```

Now use ezANOVA to rerun the one-way ANOVA. 

```{r}

ezANOVA(data=dmx4, # new dataframe
        wid=ID,  
        dv=Yij, 
        between = i,  # IV/factor of our one-way ANOVA
        detailed=TRUE
        )

```

Now that there are only two groups, you could also run this as a t-test. 
Which kind? 

ANSWER: Here, we could have run a two-sample t-test with a between-subjects design.


Run the analysis as a t-test and see if you get the same p value. Bonus points if you can see the relationship between t and F

```{r}
t.test(dmx4 %>% filter(i==2) %>% pull(Yij),
       dmx4 %>% filter(i==3) %>% pull(Yij)
       )
```
We get very (very) similar results, with a p-value equal to 0.01128 for the t-statistic (p-value = 0.01104517 for our previously computed F-statistic).


-- BONUS --
-> F = 10.8149
-> t = -3.2886
AND (-3.2886)^2 = 10.8149

So, F = t^2



